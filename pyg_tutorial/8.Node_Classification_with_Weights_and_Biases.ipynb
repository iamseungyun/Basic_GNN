{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "48079fce-256d-4377-a86e-25259f770d1c",
   "metadata": {},
   "source": [
    "### Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ada034bc-3464-4a82-a283-cd1c34ad105f",
   "metadata": {},
   "outputs": [],
   "source": [
    "enable_wandb = True\n",
    "if enable_wandb:\n",
    "    import wandb\n",
    "    wandb.login()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c65658ba-849c-4a9d-b5c0-024fbee1654e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pdb\n",
    "import torch\n",
    "import pandas\n",
    "\n",
    "os.environ['TORCH'] = torch.__version__\n",
    "print(torch.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b44bcaa-4213-4de6-8695-0a1e001d05d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from sklearn.manifold import TSNE\n",
    "\n",
    "def visualize(h, color):\n",
    "    z = TSNE(n_components=2).fit_transform(h.detach().cpu().numpy())\n",
    "    plt.figure(figsize=(10,10))\n",
    "    plt.xticks([])\n",
    "    plt.yticks([])\n",
    "    plt.scatter(z[:, 0], z[:, 1], s=70, c=color, cmap=\"Set2\")\n",
    "    plt.show()\n",
    "\n",
    "def embedding_to_wandb(h, color, key=\"embedding\"):\n",
    "    num_components = h.shape[-1]\n",
    "    df = pandas.DataFrame(data=h.detach().cpu().numpy(),\n",
    "                        columns=[f\"c_{i}\" for i in range(num_components)])\n",
    "    df[\"target\"] = color.detach().cpu().numpy().astype(\"str\")\n",
    "    cols = df.columns.tolist()\n",
    "    df = df[cols[-1:] + cols[:-1]]\n",
    "    wandb.log({key: df})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9c3a49c-0972-484b-b9fa-c66c0c41d3cc",
   "metadata": {},
   "source": [
    "## Node Classification with Graph Neural Networks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43c8fc0a-2585-45f5-bfb9-57dc54c4d265",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch_geometric.datasets import Planetoid\n",
    "from torch_geometric.transforms import NormalizeFeatures\n",
    "\n",
    "\n",
    "\n",
    "dataset = Planetoid(root='data/Planetoid', name='Cora', transform=NormalizeFeatures())\n",
    "\n",
    "print()\n",
    "print(f'Dataset: {dataset}:')\n",
    "print('======================')\n",
    "print(f'Number of graphs: {len(dataset)}')\n",
    "print(f'Number of features: {dataset.num_features}')\n",
    "print(f'Number of classes: {dataset.num_classes}')\n",
    "\n",
    "data = dataset[0]  # Get the first graph object.\n",
    "\n",
    "print()\n",
    "print(data)\n",
    "print('===========================================================================================================')\n",
    "\n",
    "# Gather some statistics about the graph.\n",
    "print(f'Number of nodes: {data.num_nodes}')\n",
    "print(f'Number of edges: {data.num_edges}')\n",
    "print(f'Average node degree: {data.num_edges / data.num_nodes:.2f}')\n",
    "print(f'Number of training nodes: {data.train_mask.sum()}')\n",
    "print(f'Training node label rate: {int(data.train_mask.sum()) / data.num_nodes:.2f}')\n",
    "print(f'Has isolated nodes: {data.has_isolated_nodes()}')\n",
    "print(f'Has self-loops: {data.has_self_loops()}')\n",
    "print(f'Is undirected: {data.is_undirected()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0528d455-246f-4dcf-9215-25686fc6c5d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.nn import Linear\n",
    "import torch.nn.functional as F\n",
    "\n",
    "\n",
    "class MLP(torch.nn.Module):\n",
    "    def __init__(self, hidden_channels):\n",
    "        super().__init__()\n",
    "        torch.manual_seed(12345)\n",
    "        self.lin1 = Linear(dataset.num_features, hidden_channels)\n",
    "        self.lin2 = Linear(hidden_channels, dataset.num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.lin1(x)\n",
    "        x = x.relu()\n",
    "        x = F.dropout(x, p=0.5, training=self.training)\n",
    "        x = self.lin2(x)\n",
    "        return x\n",
    "\n",
    "model = MLP(hidden_channels=16)\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8783a55-bef8-4345-b9ff-ebae8791e2a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "if enable_wandb:\n",
    "    wandb.init(project='node-classification')\n",
    "    summary = dict()\n",
    "    summary[\"data\"] = dict()\n",
    "    summary[\"data\"][\"num_features\"] = dataset.num_features\n",
    "    summary[\"data\"][\"num_classes\"] = dataset.num_classes\n",
    "    summary[\"data\"][\"num_nodes\"] = data.num_nodes\n",
    "    summary[\"data\"][\"num_edges\"] = data.num_edges \n",
    "    summary[\"data\"][\"has_isolated_nodes\"] = data.has_isolated_nodes()\n",
    "    summary[\"data\"][\"has_self_nodes\"] = data.has_self_loops()\n",
    "    summary[\"data\"][\"is_undirected\"] = data.is_undirected()\n",
    "    summary[\"data\"][\"num_training_nodes\"] = data.train_mask.sum()\n",
    "    wandb.summary = summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "099c7bdc-4a81-4a8a-bbfb-4340093d1408",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = MLP(hidden_channels=16)\n",
    "\n",
    "with torch.no_grad():\n",
    "  out = model(data.x)\n",
    "\n",
    "if enable_wandb:\n",
    "    embedding_to_wandb(out, color=data.y, key=\"mlp/embedding/init\")\n",
    "else:\n",
    "    visualize(out, data.y)\n",
    "\n",
    "criterion = torch.nn.CrossEntropyLoss()  # Define loss criterion.\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.01, weight_decay=5e-4)  # Define optimizer.\n",
    "\n",
    "def train():\n",
    "      model.train()\n",
    "      optimizer.zero_grad()  # Clear gradients.\n",
    "      out = model(data.x)  # Perform a single forward pass.\n",
    "      loss = criterion(out[data.train_mask], data.y[data.train_mask])  # Compute the loss solely based on the training nodes.\n",
    "      loss.backward()  # Derive gradients.\n",
    "      optimizer.step()  # Update parameters based on gradients.\n",
    "      return loss\n",
    "\n",
    "def test():\n",
    "      model.eval()\n",
    "      out = model(data.x)\n",
    "      pred = out.argmax(dim=1)  # Use the class with highest probability.\n",
    "      test_correct = pred[data.test_mask] == data.y[data.test_mask]  # Check against ground-truth labels.\n",
    "      test_acc = int(test_correct.sum()) / int(data.test_mask.sum())  # Derive ratio of correct predictions.\n",
    "      return test_acc\n",
    "\n",
    "for epoch in range(1, 201):\n",
    "    loss = train()\n",
    "    if enable_wandb:\n",
    "        wandb.log({\"mlp/loss\": loss})\n",
    "    print(f'Epoch: {epoch:03d}, Loss: {loss:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5c07754-44e1-40d2-90b9-0365d90342ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch_geometric.nn import GCNConv\n",
    "\n",
    "\n",
    "class GCN(torch.nn.Module):\n",
    "    def __init__(self, hidden_channels):\n",
    "        super().__init__()\n",
    "        torch.manual_seed(1234567)\n",
    "        self.conv1 = GCNConv(dataset.num_features, hidden_channels)\n",
    "        self.conv2 = GCNConv(hidden_channels, dataset.num_classes)\n",
    "\n",
    "    def forward(self, x, edge_index):\n",
    "        x = self.conv1(x, edge_index)\n",
    "        x = x.relu()\n",
    "        x = F.dropout(x, p=0.5, training=self.training)\n",
    "        x = self.conv2(x, edge_index)\n",
    "        return x\n",
    "\n",
    "model = GCN(hidden_channels=16)\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd2ac80f-0490-408e-8843-9055130b18d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = GCN(hidden_channels=16)\n",
    "model.eval()\n",
    "\n",
    "out = model(data.x, data.edge_index)\n",
    "\n",
    "if enable_wandb:\n",
    "    embedding_to_wandb(out, color=data.y, key=\"gcn/embedding/init\")\n",
    "else:\n",
    "    visualize(out, data.y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec486c2d-4da7-435b-be34-cb4d589c28a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = GCN(hidden_channels=16)\n",
    "if enable_wandb:\n",
    "    wandb.watch(model)\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.01, weight_decay=5e-4)\n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "def train():\n",
    "      model.train()\n",
    "      optimizer.zero_grad()  # Clear gradients.\n",
    "      out = model(data.x, data.edge_index)  # Perform a single forward pass.\n",
    "      loss = criterion(out[data.train_mask], data.y[data.train_mask])  # Compute the loss solely based on the training nodes.\n",
    "      loss.backward()  # Derive gradients.\n",
    "      optimizer.step()  # Update parameters based on gradients.\n",
    "      return loss\n",
    "\n",
    "def test():\n",
    "      model.eval()\n",
    "      out = model(data.x, data.edge_index)\n",
    "      pred = out.argmax(dim=1)  # Use the class with highest probability.\n",
    "      test_correct = pred[data.test_mask] == data.y[data.test_mask]  # Check against ground-truth labels.\n",
    "      test_acc = int(test_correct.sum()) / int(data.test_mask.sum())  # Derive ratio of correct predictions.\n",
    "      return test_acc\n",
    "\n",
    "\n",
    "for epoch in range(1, 101):\n",
    "    loss = train()\n",
    "    if enable_wandb:\n",
    "        wandb.log({\"gcn/loss\": loss})\n",
    "    print(f'Epoch: {epoch:03d}, Loss: {loss:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e61d04e7-7011-4344-945e-eb5da622c220",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_acc = test()\n",
    "print(f'Test Accuracy: {test_acc:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20967999-7166-4210-861e-c96f333d3171",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()\n",
    "\n",
    "out = model(data.x, data.edge_index)\n",
    "\n",
    "if enable_wandb:\n",
    "    wandb.summary[\"gcn/accuracy\"] = test_acc\n",
    "    wandb.log({\"gcn/accuracy\": test_acc})\n",
    "    embedding_to_wandb(out, color=data.y, key=\"gcn/embedding/trained\")\n",
    "    wandb.finish()\n",
    "else:\n",
    "    visualize(out, data.y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5220e6df-b472-4a3f-897c-9297d966ee1d",
   "metadata": {},
   "source": [
    "## Using W&B Sweeps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c23b37f1-3add-4f78-816a-1c0596241c6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "assert enable_wandb, \"W&B not enabled. Please, enable W&B and restart the notebook\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0261ba2-460b-4e00-a186-44216a4e7fe1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tqdm\n",
    "\n",
    "def agent_fn():\n",
    "    wandb.init()\n",
    "    model = GCN(hidden_channels=wandb.config.hidden_channels)\n",
    "    wandb.watch(model)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        out = model(data.x, data.edge_index)\n",
    "        embedding_to_wandb(out, color=data.y, key='gcn/embedding/init')\n",
    "\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=wandb.config.lr, weight_decay=wandb.config.weight_decay)\n",
    "    criterion = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "    def train():\n",
    "        model.train()\n",
    "        optimizer.zero_grad()\n",
    "        out = model(data.x, data.edge_index)\n",
    "        loss = criterion(out[data.train_mask], data.y[data.train_mask])\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        return loss\n",
    "\n",
    "    def test():\n",
    "        model.eval()\n",
    "        out = model(data.x, data.edge_index)\n",
    "        pred = out.argmax(dim=1)\n",
    "        test_correct = pred[data.test_mask] == data.y[data.test_mask]\n",
    "        test_acc = int(test_correct.sum()) / int(data.test_mask.sum())\n",
    "        return test_acc\n",
    "\n",
    "    for epoch in tqdm.tqdm(range(1, 101)):\n",
    "        loss = train()\n",
    "        wandb.log({\"gcn/loss\": loss})\n",
    "\n",
    "    model.eval()\n",
    "\n",
    "    out = model(data.x, data.edge_index)\n",
    "    test_acc = test()\n",
    "    wandb.summary[\"gcn/accuracy\"] = test_acc\n",
    "    wandb.log({\"gcn/accuracy\": test_acc})\n",
    "    embedding_to_wandb(out, color=data.y, key=\"gcn/embedding/trained\")\n",
    "    wandb.finish()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2ad86c3-6e49-4b02-b1d9-76e821f6240f",
   "metadata": {},
   "outputs": [],
   "source": [
    "sweep_config = {\n",
    "    \"name\": \"gcn-sweep\",\n",
    "    \"method\": \"bayes\",\n",
    "    \"metric\": {\n",
    "        \"name\": \"gcn/accuracy\",\n",
    "        \"goal\": \"maximize\",\n",
    "    },\n",
    "    \"parameters\": {\n",
    "        \"hidden_channels\": {\n",
    "            \"values\": [8, 16, 32]\n",
    "        },\n",
    "        \"weight_decay\": {\n",
    "            \"distribution\": \"normal\",\n",
    "            \"mu\": 5e-4,\n",
    "            \"sigma\": 1e-5,\n",
    "        },\n",
    "        \"lr\": {\n",
    "            \"min\": 1e-4,\n",
    "            \"max\": 1e-3\n",
    "        }\n",
    "    }\n",
    "}\n",
    "\n",
    "# Register the Sweep with W&B\n",
    "sweep_id = wandb.sweep(sweep_config, project=\"node-classification\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ba218bc-3971-48df-9b0b-09b2b1bdfb30",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run the Sweeps agent\n",
    "wandb.agent(sweep_id, project=\"node-classification\", function=agent_fn, count=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5d6d76f-f592-4c06-85b3-b8e208feae2c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gnn",
   "language": "python",
   "name": "gnn"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
